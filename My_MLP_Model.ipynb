{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e63309f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 23:37:45.426931: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "585e1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MY_MLP_Model:\n",
    "    def __init__(self):\n",
    "        self.weights_input_hidden = None\n",
    "        self.bias_hidden = None\n",
    "\n",
    "    def load_model(self):\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "        return x_train, y_train, x_test, y_test\n",
    "    \n",
    "    def define_input_size(self, x_train):\n",
    "        image_size = x_train.shape[1]\n",
    "        # This is the total count of the features for each image. \n",
    "        # In MNIST Dataset, each image is 28 pixels wide and 28 pixels tall.\n",
    "        input_size = image_size ** 2\n",
    "        return input_size\n",
    "\n",
    "    # By flattening the image pixels, this method converts a 2D structure into a 1D structure by taking all the pixel values \n",
    "    # in the 28x28 grid and arranging them in a single line which is ht input_size\n",
    "    def resize_training_data(self, x_train, x_test):\n",
    "        input_size = self.define_input_size(x_train)\n",
    "        resized_x_train = np.reshape(x_train, [-1, input_size])\n",
    "        resized_x_test = np.reshape(x_test, [-1, input_size])\n",
    "        return resized_x_train, resized_x_test\n",
    "\n",
    "    # the following method changes the data type to float32 which was before integer\n",
    "    # it scales the image between 0 and 1, each pixel in the image contains the value between 0 and 255\n",
    "    # 0 means being completely black (dark) and 255 means being completely white (bright)\n",
    "    def normalize_training_data(self, x_train, x_test):\n",
    "        resized_x_train, resized_x_test = self.resize_training_data(x_train, x_test)\n",
    "        normalize_x_train = resized_x_train.astype('float32') / 255\n",
    "        normalize_x_test = resized_x_test.astype('float32') / 255\n",
    "        return normalize_x_train, normalize_x_test\n",
    "    \n",
    "    def preprocess_labels(self, y_train, y_test):\n",
    "        num_labels = len(np.unique(y_train))\n",
    "        one_hot_y_train = self.to_one_hot_encoding(y_train)\n",
    "        one_hot_y_test = self.to_one_hot_encoding(y_test)\n",
    "        return one_hot_y_train, one_hot_y_test, num_labels\n",
    "    \n",
    "    # The following method I write replaces all labeled values in y_train and y_test with one-hot encoding. \n",
    "    # For instance, it changes the value of 4 to [0, 0, 0, 0, 1 0, 0, 0, 0, 0].\n",
    "    def to_one_hot_encoding(self, datasets):\n",
    "        set_all_zeros = np.zeros(10, dtype=int)\n",
    "        changed_to_one_hot = []\n",
    "\n",
    "        for i in range(len(datasets)):\n",
    "            for j in range(10):\n",
    "                if datasets[i] == j:\n",
    "                    set_all_zeros[j] = 1\n",
    "                    changed_to_one_hot.append(set_all_zeros)\n",
    "                    set_all_zeros = np.zeros(10, dtype=int)\n",
    "                    break\n",
    "        return changed_to_one_hot\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def dropout(self, x, rate):\n",
    "        mask = np.random.rand(*x.shape) < rate\n",
    "        return x * mask / (1 - rate)\n",
    "    \n",
    "    def set_hyperparameters(self, x_train):\n",
    "        input_size = self.define_input_size(x_train)\n",
    "        hidden_units = 256\n",
    "        self.weights_input_hidden = np.random.randn(input_size, hidden_units)\n",
    "        self.bias_hidden = np.ones((hidden_units,), dtype=float)\n",
    "        batch_size = 128\n",
    "        learning_rate = 0.05\n",
    "        epoch = 20\n",
    "        return batch_size, epoch, learning_rate\n",
    "\n",
    "\n",
    "    def train_model(self, x_train, y_train):\n",
    "        batch, epoch, learning_rate = self.set_hyperparameters(x_train)\n",
    "        train_features = x_train.shape[1]\n",
    "        self.weights_input_hidden = np.zeros((train_features, 10))\n",
    "        self.bias_hidden = 0\n",
    "\n",
    "        for _ in range(epoch):\n",
    "            activation = np.dot(x_train, self.weights_input_hidden) + self.bias_hidden      \n",
    "\n",
    "            y_predict = self.step_function(activation)\n",
    "\n",
    "            update_weight = learning_rate * np.dot(x_train.T, (y_train - y_predict))\n",
    "            update_bias = learning_rate * np.sum(y_train - y_predict)\n",
    "\n",
    "            self.weights_input_hidden += update_weight\n",
    "            self.bias_hidden += update_bias\n",
    "        return self.weights_input_hidden, self.bias_hidden\n",
    "\n",
    "    def step_function(self, x_train):\n",
    "        return np.eye(10)[np.argmax(x_train, axis=1)].reshape(-1, 10)\n",
    "\n",
    "    def predict(self, x_train):\n",
    "        activate = np.dot(x_train, self.weights_input_hidden) + self.bias_hidden\n",
    "        return self.step_function(activate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72e2bb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  96.65%\n",
      "Testing Accuracy: 96.73%\n",
      "Accuracy: 96.65%\n"
     ]
    }
   ],
   "source": [
    "# instantiate the My_MLP_Model class\n",
    "model_call = MY_MLP_Model()\n",
    "x_train, y_train, x_test, y_test = model_call.load_model()\n",
    "one_hot_y_train, one_hot_y_test, num_labels = model_call.preprocess_labels(y_train, y_test)\n",
    "x_train_normalized, x_test_normalized = model_call.normalize_training_data(x_train, x_test)\n",
    "\n",
    "w, b = model_call.train_model(x_train_normalized[:1000], one_hot_y_train[:1000])\n",
    "\n",
    "y_p_trained = model_call.predict(x_train_normalized)\n",
    "y_p_test = model_call.predict(x_test_normalized)\n",
    "\n",
    "print(\"Training Accuracy:  %.2f%%\" % (100 - np.mean(np.abs(y_p_trained - one_hot_y_train)) * 100))\n",
    "print(\"Testing Accuracy: %.2f%%\" %  (100 - np.mean(np.abs(y_p_test - one_hot_y_test)) * 100))\n",
    "\n",
    "prediction = model_call.predict(x_train_normalized)\n",
    "predicted_one_hot = model_call.step_function(prediction)\n",
    "\n",
    "true_one_hot = one_hot_y_train\n",
    "\n",
    "accuracy = np.mean(np.equal(predicted_one_hot, true_one_hot))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd44d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiassignment",
   "language": "python",
   "name": "aiassignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
